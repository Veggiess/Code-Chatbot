from flask import Flask, request, jsonify, render_template
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.messages import HumanMessage, AIMessage
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_community.document_loaders import WebBaseLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_chroma import Chroma
from langchain.tools.retriever import create_retriever_tool
from langgraph.prebuilt import chat_agent_executor
from langgraph.checkpoint.sqlite import SqliteSaver
from dotenv import load_dotenv
from datetime import datetime
import os
import logging
import sys
import bs4
import io
import subprocess
import re

# Configure logging
logging.basicConfig(level=logging.DEBUG)

# Load environment variables
load_dotenv()

# Initialize the model
model = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)

# Set environment variables
os.environ["TAVILY_API_KEY"] = os.getenv("TAVILY_API_KEY")
os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY")

# Initialize components
memory = SqliteSaver.from_conn_string(":memory:")
search = TavilySearchResults(max_results=2)

# Load and process documents
bs4_strainer = bs4.SoupStrainer(class_=("post-title", "post-header", "post-content"))
loader = WebBaseLoader(
    web_paths=("https://lilianweng.github.io/posts/2023-06-23-agent/",),
    bs_kwargs={"parse_only": bs4_strainer},
)
docs = loader.load()

text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000, chunk_overlap=200, add_start_index=True
)
all_splits = text_splitter.split_documents(docs)

vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())
retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={"k": 6})

retriever_tool = create_retriever_tool(
    retriever,
    "langsmith_search",
    "Search for information about LangSmith. For any questions about LangSmith, you must use this tool!",
)

tools = [search, retriever_tool]

# Create agent executor
agent_executor = chat_agent_executor.create_tool_calling_executor(model, tools, checkpointer=memory)

# Config with required thread_id
config = {"configurable": {"thread_id": "abc123"}}

# Chat history file
chat_history_file = "chat_history.txt"

# ICL examples file
icl_examples_file = "icl_examples.txt"

# Function to load chat history from file
def load_chat_history(file_path):
    messages = []
    if os.path.exists(file_path):
        with open(file_path, "r") as file:
            lines = file.readlines()
            for line in lines:
                if line.startswith("[User]: "):
                    content = line[len("[User]: "):].strip()
                    messages.append(HumanMessage(content=content))
                elif line.startswith("[AI]: "):
                    content = line[len("[AI]: "):].strip()
                    messages.append(AIMessage(content=content))
    return messages

# Function to save a message to file
def save_message_to_file(file_path, role, content):
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')  # Get current timestamp
    with open(file_path, "a") as file:
        file.write(f"[{timestamp}] | [{role}]: {content}\n")

# Function to execute Python code
def execute_python_code(code):
    try:
        old_stdout = sys.stdout
        sys.stdout = new_stdout = io.StringIO()
        exec(code, {})
        result = new_stdout.getvalue()
    except Exception as e:
        result = str(e)
    finally:
        sys.stdout = old_stdout
    return result

# Function to execute Java code
def execute_java_code(code):
    try:
        # Extract the class name from the Java code
        match = re.search(r'public\s+class\s+(\w+)', code)
        if not match:
            return "Error: No public class found in the Java code."
        
        class_name = match.group(1)
        file_name = f"{class_name}.java"
        
        # Write the Java code to a temporary file
        with open(file_name, "w") as file:
            file.write(code)
        
        # Compile the Java code
        compile_process = subprocess.run(["javac", file_name], capture_output=True, text=True)
        if compile_process.returncode != 0:
            return compile_process.stderr
        
        # Run the compiled Java code
        run_process = subprocess.run(["java", class_name], capture_output=True, text=True)
        if run_process.returncode != 0:
            return run_process.stderr
        
        return run_process.stdout
    except Exception as e:
        return str(e)
    finally:
        # Clean up temporary files
        if os.path.exists(file_name):
            os.remove(file_name)
        class_file = f"{class_name}.class"
        if os.path.exists(class_file):
            os.remove(class_file)

# Function to load ICL examples from file
def load_icl_examples(file_path):
    messages = []
    if os.path.exists(file_path):
        with open(file_path, "r") as file:
            lines = file.readlines()
            for line in lines:
                if line.startswith("[User]: "):
                    content = line[len("[User]: "):].strip()
                    messages.append(HumanMessage(content=content))
                elif line.startswith("[AI]: "):
                    content = line[len("[AI]: "):].strip()
                    messages.append(AIMessage(content=content))
    return messages

# Initialize Flask app
app = Flask(__name__)

# Define the main route
@app.route('/')
def index():
    return render_template('index.html')

# Define the route to process user input
@app.route('/process', methods=['POST'])
def process():
    try:
        user_input = request.json.get('input')
        if not user_input:
            return jsonify({'error': 'Invalid input'}), 400
        
        logging.debug(f"User input received: {user_input}")

        # Load previous chat history
        messages = load_chat_history(chat_history_file)

        # Load ICL examples
        icl_examples = load_icl_examples(icl_examples_file)

        # Add in-context examples to the beginning of the messages
        messages = icl_examples + messages

        usr_msg = HumanMessage(content=user_input)
        messages.append(usr_msg)
        save_message_to_file(chat_history_file, "User", user_input)
        
        logging.debug(f"Invoking agent with messages: {messages}")

        if user_input.startswith("python:"):
            code = user_input[len("python:"):].strip()
            result = execute_python_code(code)
            ai_msg_content = f"Execution result:\n{result}"
        elif user_input.startswith("java:"):
            code = user_input[len("java:"):].strip()
            result = execute_java_code(code)
            ai_msg_content = f"Execution result:\n{result}"
        else:
            response = agent_executor.invoke({"messages": messages}, config=config)
            ai_msg_content = response["messages"][-1].content
        
        logging.debug(f"AI response: {ai_msg_content}")

        ai_msg = AIMessage(content=ai_msg_content)
        messages.append(ai_msg)
        save_message_to_file(chat_history_file, "AI", ai_msg.content)

        return jsonify({'result': ai_msg.content})
    except Exception as e:
        logging.error(f"Error processing request: {e}")
        return jsonify({'error': 'Failed to process request'}), 500

if __name__ == '__main__':
    app.run(debug=True)